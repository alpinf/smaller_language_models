{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggqo0gAJQVei"
      },
      "source": [
        "# Vocabulary Trimming of a T5 model\n",
        "\n",
        "This notebook reduced the size of the tokenizer and of the embedding and decoding layer of a T5 model by removing the tokens that are not part of a target language. The goal is to transform a multilingual T5 model into a smaller, more efficient monolingual model while preserving the original model's accuracy for the target language.\n",
        "\n",
        "This notebook follows [this blog](https://towardsdatascience.com/how-to-adapt-a-multilingual-t5-model-for-a-single-language-b9f94f3d9c90) that comes from the paper [Load What You Need](https://aclanthology.org/2020.sustainlp-1.16.pdf).\n",
        "\n",
        "We run the procedure using the model mT5 and French as the target language.\n",
        "\n",
        "A complete description of this and other methods for reducing model size is available [here](https://github.com/alpinf/smaller_language_models/blob/main/Smaller_LLMs.md).\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alpinf/smaller_language_models/blob/main/notebooks/vocab_trim_mT5.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2sksNctaOnw"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cVHKkCJZaOnw"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' not in sys.modules:\n",
        "    print(\"Warning: The setup was only tested in Google Colab\")\n",
        "\n",
        "!python -m pip install pandas==2.2.2 torch==2.3.1 transformers==4.41.2 datasets==2.20.0 sentencepiece==0.2.0 gdown tqdm --quiet --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wi9ZGrGNQVem"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import gdown\n",
        "import pandas as pd\n",
        "from sentencepiece import sentencepiece_model_pb2 as spmp\n",
        "import torch\n",
        "from tqdm.auto import tqdm, trange\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eNxlGc2wcT0y"
      },
      "outputs": [],
      "source": [
        "out_dir = \"./out\"\n",
        "data_dir = \"./data\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "os.makedirs(data_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aPdkqBGJaOny"
      },
      "outputs": [],
      "source": [
        "def download_file_from_google_drive(file_id, destination):\n",
        "    \"\"\"\n",
        "    Example usage:\n",
        "    File link on Gdrive: https://drive.google.com/file/d/188r2cctPaqmuXnwer3KBpIHpftnE9tCb/view?usp=drive_link\n",
        "\n",
        "    download_file_from_google_drive(\"188r2cctPaqmuXnwer3KBpIHpftnE9tCb\", \"./data/\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "        gdown.download(url, output=destination, quiet=False)\n",
        "        print(f\"File downloaded from Google Drive to {destination}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading file: {e}\")\n",
        "        raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTEyDHu5QVen"
      },
      "source": [
        "Import the T5 model and its tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQX5TXpwQVeo",
        "outputId": "0c3ee60a-1554-4145-eb17-81d52918aa0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained('google/mt5-small')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQShdcnBQVep"
      },
      "source": [
        "We can understand the percentage of parameters in the embedding and decoding layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iePu6uQ7QVep",
        "outputId": "320003ba-52b3-4f8d-894b-95a2001f4f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of parameters in the encoding layer: 42.7%\n",
            "Percentage of parameters in the decoding layer: 42.7%\n",
            "The length of the mT5 vocabulary is 250100\n"
          ]
        }
      ],
      "source": [
        "def parameters_layer(layer): # returns the number of parameters in a layer\n",
        "    return sum(p.numel() for p in layer.parameters())\n",
        "\n",
        "num_params = parameters_layer(model)\n",
        "# shared is the encoder layer, lm_head is the decoder layer\n",
        "print(f\"Percentage of parameters in the encoding layer: {100 * parameters_layer(model.shared) / parameters_layer(model):.1f}%\")   # 42.7%\n",
        "print(f\"Percentage of parameters in the decoding layer: {100 * parameters_layer(model.lm_head) / parameters_layer(model):.1f}%\")  # 42.7%\n",
        "print(f\"The length of the mT5 vocabulary is {len(list(tokenizer.get_vocab().keys()))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16ZjV9YEQVeq"
      },
      "source": [
        "## Selecting the vocabulary\n",
        "To select the vocabulary we use the [Leipzig corpora collection](https://wortschatz.uni-leipzig.de/en/download/French), but any corpus in the target language can be used. The data we use is part of the **French _News_** section of 2023 with 1 million sentences.\n",
        "\n",
        "The corpus can be downloaded from the link above. We keep a backup copy on our drive for reproducibility.\n",
        "\n",
        "First, we tokenized the entire corpus and kept track of the most frequent tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "25db9decca324ac1af4bb28c834862f3",
            "e1720e0f21364e22b3c05986ecd79972",
            "1cc14d19698e46c6b5121ead000aff0b",
            "278ac12a13b541118f6642901d324417",
            "a9f4b5b52598490386d9cf536c3745e1",
            "da2e61840f404dd18776195194d7a623",
            "1d32233015444285a9d8ca54de5345a7",
            "3548365e23cc47fc97d6683cc9515e4f",
            "1c4b62a0444e4927a35a925454b1ef17",
            "32a01988cb5447fc9e9f6644e309c098",
            "14e181d2807549dabcdd5c2688b64add"
          ]
        },
        "id": "XC3okKqYQVeq",
        "outputId": "a048a1c7-d061-468a-dd78-e5be2732905b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25db9decca324ac1af4bb28c834862f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total number of tokens seen in the dataset is 37866826\n",
            "The number of unique tokens in the dataset is 63347\n",
            "The dataset covers 25.3% of the mT5 vocabulary.\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset manually from the link above or use a copy on our drive\n",
        "data_path = f\"{data_dir}/fra_news_2023_1M-sentences.txt\"\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    download_file_from_google_drive(\"171RgrkXuWHfY-4BzHR8JEvYp9-D8yPqA\", data_path)\n",
        "    print(\"Dataset downloaded from drive\")\n",
        "\n",
        "df_fr = pd.read_table(data_path, header=None, quoting=csv.QUOTE_NONE,\n",
        "                    dtype={0: int, 1: str})\n",
        "df_fr = df_fr.rename(columns={0: \"idx\", 1: \"text\"})\n",
        "cnt = Counter()\n",
        "\n",
        "total_tokens = 0\n",
        "for text in tqdm(df_fr.text):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    cnt.update(tokens)\n",
        "    total_tokens += len(tokens)\n",
        "\n",
        "print(f\"The total number of tokens seen in the dataset is {total_tokens}\")\n",
        "print(f\"The number of unique tokens in the dataset is {len(cnt)}\")\n",
        "print(f\"The dataset covers {100 * len(cnt) / tokenizer.vocab_size:.1f}% of the mT5 vocabulary.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFJ7ux9GQVer"
      },
      "source": [
        "We can decide how many tokens to keep based on what percentage of the corpus we want to cover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhj6oCxWQVer",
        "outputId": "016d497d-0506-47c1-ec12-adc22d16f9ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10000 most common tokens cover 97.23% of the dataset\n",
            "The 20000 most common tokens cover 99.14% of the dataset\n",
            "The 42115 most common tokens cover 99.90% of the dataset\n",
            "The 60000 most common tokens cover 99.99% of the dataset\n",
            "\n",
            "We will keep 42115 tokens to cover 99.9% of the dataset\n"
          ]
        }
      ],
      "source": [
        "percentage_to_keep = 0.999\n",
        "\n",
        "cum_sum = 0\n",
        "for i, (k, v) in enumerate(cnt.most_common()):\n",
        "    cum_sum += v\n",
        "    if cum_sum / sum(cnt.values()) > percentage_to_keep:\n",
        "        break\n",
        "    num_tokens = i + 1 # we save the number of tokens to keep\n",
        "\n",
        "for top in 10_000, 20_000, num_tokens, 60_000:\n",
        "    print(f\"The {top} most common tokens cover {100 * sum(v for k, v in cnt.most_common(top)) / sum(cnt.values()):.2f}% of the dataset\")\n",
        "\n",
        "print(f\"\\nWe will keep {num_tokens} tokens to cover {percentage_to_keep * 100}% of the dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fshfSgdQVer"
      },
      "source": [
        "We start by keeping the first 259 tokens. In these tokens there are the special tokens (`<pad>`, `</s>`, `<unk>`), fundamental for fine-tuning, the 256 hexadecimal (`<0x00>`, `<0x01>`, ...) tokens that can be used to map every character using their ASCII code. These tokens will be kept so that even if the model encounters a character that is not in the vocabulary it can still represent it.\n",
        "\n",
        "We also keep the last 100 tokens; these tokens are extra tokens (`▁<extra_id_0>`, `▁<extra_id_1>`, ...) that can be used for different purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROn1ow4JQVes",
        "outputId": "2d95310a-3ba4-470b-8f31-3f37e5a5d66f",
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Special tokens: ['<pad>', '</s>', '<unk>']\n",
            "Hexadecimal tokens: ['<0x00>', '<0x01>', '<0x02>', '<0x03>', '<0x04>', '<0x05>', '<0x06>', '<0x07>', '<0x08>', '<0x09>', '<0x0A>', '<0x0B>', '<0x0C>', '<0x0D>', '<0x0E>', '<0x0F>', '<0x10>', '<0x11>', '<0x12>', '<0x13>', '<0x14>', '<0x15>', '<0x16>', '<0x17>', '<0x18>', '<0x19>', '<0x1A>', '<0x1B>', '<0x1C>', '<0x1D>', '<0x1E>', '<0x1F>', '<0x20>', '<0x21>', '<0x22>', '<0x23>', '<0x24>', '<0x25>', '<0x26>', '<0x27>', '<0x28>', '<0x29>', '<0x2A>', '<0x2B>', '<0x2C>', '<0x2D>', '<0x2E>', '<0x2F>', '<0x30>', '<0x31>', '<0x32>', '<0x33>', '<0x34>', '<0x35>', '<0x36>', '<0x37>', '<0x38>', '<0x39>', '<0x3A>', '<0x3B>', '<0x3C>', '<0x3D>', '<0x3E>', '<0x3F>', '<0x40>', '<0x41>', '<0x42>', '<0x43>', '<0x44>', '<0x45>', '<0x46>', '<0x47>', '<0x48>', '<0x49>', '<0x4A>', '<0x4B>', '<0x4C>', '<0x4D>', '<0x4E>', '<0x4F>', '<0x50>', '<0x51>', '<0x52>', '<0x53>', '<0x54>', '<0x55>', '<0x56>', '<0x57>', '<0x58>', '<0x59>', '<0x5A>', '<0x5B>', '<0x5C>', '<0x5D>', '<0x5E>', '<0x5F>', '<0x60>', '<0x61>', '<0x62>', '<0x63>', '<0x64>', '<0x65>', '<0x66>', '<0x67>', '<0x68>', '<0x69>', '<0x6A>', '<0x6B>', '<0x6C>', '<0x6D>', '<0x6E>', '<0x6F>', '<0x70>', '<0x71>', '<0x72>', '<0x73>', '<0x74>', '<0x75>', '<0x76>', '<0x77>', '<0x78>', '<0x79>', '<0x7A>', '<0x7B>', '<0x7C>', '<0x7D>', '<0x7E>', '<0x7F>', '<0x80>', '<0x81>', '<0x82>', '<0x83>', '<0x84>', '<0x85>', '<0x86>', '<0x87>', '<0x88>', '<0x89>', '<0x8A>', '<0x8B>', '<0x8C>', '<0x8D>', '<0x8E>', '<0x8F>', '<0x90>', '<0x91>', '<0x92>', '<0x93>', '<0x94>', '<0x95>', '<0x96>', '<0x97>', '<0x98>', '<0x99>', '<0x9A>', '<0x9B>', '<0x9C>', '<0x9D>', '<0x9E>', '<0x9F>', '<0xA0>', '<0xA1>', '<0xA2>', '<0xA3>', '<0xA4>', '<0xA5>', '<0xA6>', '<0xA7>', '<0xA8>', '<0xA9>', '<0xAA>', '<0xAB>', '<0xAC>', '<0xAD>', '<0xAE>', '<0xAF>', '<0xB0>', '<0xB1>', '<0xB2>', '<0xB3>', '<0xB4>', '<0xB5>', '<0xB6>', '<0xB7>', '<0xB8>', '<0xB9>', '<0xBA>', '<0xBB>', '<0xBC>', '<0xBD>', '<0xBE>', '<0xBF>', '<0xC0>', '<0xC1>', '<0xC2>', '<0xC3>', '<0xC4>', '<0xC5>', '<0xC6>', '<0xC7>', '<0xC8>', '<0xC9>', '<0xCA>', '<0xCB>', '<0xCC>', '<0xCD>', '<0xCE>', '<0xCF>', '<0xD0>', '<0xD1>', '<0xD2>', '<0xD3>', '<0xD4>', '<0xD5>', '<0xD6>', '<0xD7>', '<0xD8>', '<0xD9>', '<0xDA>', '<0xDB>', '<0xDC>', '<0xDD>', '<0xDE>', '<0xDF>', '<0xE0>', '<0xE1>', '<0xE2>', '<0xE3>', '<0xE4>', '<0xE5>', '<0xE6>', '<0xE7>', '<0xE8>', '<0xE9>', '<0xEA>', '<0xEB>', '<0xEC>', '<0xED>', '<0xEE>', '<0xEF>', '<0xF0>', '<0xF1>', '<0xF2>', '<0xF3>', '<0xF4>', '<0xF5>', '<0xF6>', '<0xF7>', '<0xF8>', '<0xF9>', '<0xFA>', '<0xFB>', '<0xFC>', '<0xFD>', '<0xFE>', '<0xFF>']\n",
            "Last 100 tokens: ['▁<extra_id_99>', '▁<extra_id_98>', '▁<extra_id_97>', '▁<extra_id_96>', '▁<extra_id_95>', '▁<extra_id_94>', '▁<extra_id_93>', '▁<extra_id_92>', '▁<extra_id_91>', '▁<extra_id_90>', '▁<extra_id_89>', '▁<extra_id_88>', '▁<extra_id_87>', '▁<extra_id_86>', '▁<extra_id_85>', '▁<extra_id_84>', '▁<extra_id_83>', '▁<extra_id_82>', '▁<extra_id_81>', '▁<extra_id_80>', '▁<extra_id_79>', '▁<extra_id_78>', '▁<extra_id_77>', '▁<extra_id_76>', '▁<extra_id_75>', '▁<extra_id_74>', '▁<extra_id_73>', '▁<extra_id_72>', '▁<extra_id_71>', '▁<extra_id_70>', '▁<extra_id_69>', '▁<extra_id_68>', '▁<extra_id_67>', '▁<extra_id_66>', '▁<extra_id_65>', '▁<extra_id_64>', '▁<extra_id_63>', '▁<extra_id_62>', '▁<extra_id_61>', '▁<extra_id_60>', '▁<extra_id_59>', '▁<extra_id_58>', '▁<extra_id_57>', '▁<extra_id_56>', '▁<extra_id_55>', '▁<extra_id_54>', '▁<extra_id_53>', '▁<extra_id_52>', '▁<extra_id_51>', '▁<extra_id_50>', '▁<extra_id_49>', '▁<extra_id_48>', '▁<extra_id_47>', '▁<extra_id_46>', '▁<extra_id_45>', '▁<extra_id_44>', '▁<extra_id_43>', '▁<extra_id_42>', '▁<extra_id_41>', '▁<extra_id_40>', '▁<extra_id_39>', '▁<extra_id_38>', '▁<extra_id_37>', '▁<extra_id_36>', '▁<extra_id_35>', '▁<extra_id_34>', '▁<extra_id_33>', '▁<extra_id_32>', '▁<extra_id_31>', '▁<extra_id_30>', '▁<extra_id_29>', '▁<extra_id_28>', '▁<extra_id_27>', '▁<extra_id_26>', '▁<extra_id_25>', '▁<extra_id_24>', '▁<extra_id_23>', '▁<extra_id_22>', '▁<extra_id_21>', '▁<extra_id_20>', '▁<extra_id_19>', '▁<extra_id_18>', '▁<extra_id_17>', '▁<extra_id_16>', '▁<extra_id_15>', '▁<extra_id_14>', '▁<extra_id_13>', '▁<extra_id_12>', '▁<extra_id_11>', '▁<extra_id_10>', '▁<extra_id_9>', '▁<extra_id_8>', '▁<extra_id_7>', '▁<extra_id_6>', '▁<extra_id_5>', '▁<extra_id_4>', '▁<extra_id_3>', '▁<extra_id_2>', '▁<extra_id_1>', '▁<extra_id_0>']\n"
          ]
        }
      ],
      "source": [
        "print(f\"Special tokens: {tokenizer.convert_ids_to_tokens(range(3))}\")\n",
        "print(f\"Hexadecimal tokens: {tokenizer.convert_ids_to_tokens(range(3, 256 + 3))}\")\n",
        "print(f\"Last 100 tokens: {tokenizer.convert_ids_to_tokens(range(tokenizer.vocab_size - 100, tokenizer.vocab_size))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JotctNcRQVes",
        "outputId": "17c91db8-a7c9-4f84-d1db-f951bc55ed8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The final number of tokens, including the special tokens, is 42473\n",
            "The percentage of the mT5 vocabulary we will keep is 17.0%\n"
          ]
        }
      ],
      "source": [
        "new_tokens = set(range(3 + 256)) # first 259 tokens\n",
        "for i, (k, v) in enumerate(cnt.most_common(num_tokens)):\n",
        "    if k not in new_tokens:\n",
        "        new_tokens.add(k)\n",
        "for t in range(tokenizer.vocab_size - 100, tokenizer.vocab_size): # last 100 tokens\n",
        "    new_tokens.add(t)\n",
        "kept_ids = sorted(new_tokens)\n",
        "\n",
        "print(f\"The final number of tokens, including the special tokens, is {len(kept_ids)}\")\n",
        "print(f\"The percentage of the mT5 vocabulary we will keep is {100 * len(kept_ids) / tokenizer.vocab_size:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9q-aLJ2QVet"
      },
      "source": [
        "## Reducing the embedding layer and the decoder layer\n",
        "We start by remapping the embedding and decoding layers of the T5 model to the smaller one.\n",
        "\n",
        "To each new token of the smaller vocabulary is assigned an index, from 0 to the total number of kept tokens. (This is done using ```enumerate```). Then a new embedding matrix is created where each row corresponds to the original row of the T5 model of the relative token. The same is done for the decoder layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "J_jWa3iRQVeu"
      },
      "outputs": [],
      "source": [
        "new_size = len(kept_ids)\n",
        "new_emb = torch.nn.Embedding(new_size, model.shared.embedding_dim)\n",
        "new_head = torch.nn.Linear(in_features=model.lm_head.in_features, out_features=new_size, bias=False)\n",
        "for new_id, old_id in enumerate(kept_ids):\n",
        "    # we map the old weights to the new weights, both for the embedding and the head\n",
        "    new_emb.weight.data[new_id] = model.shared.weight.data[old_id]\n",
        "    new_head.weight.data[new_id] = model.lm_head.weight.data[old_id]\n",
        "\n",
        "# we update the model weights\n",
        "model.shared.weight = new_emb.weight\n",
        "model.lm_head.weight = new_head.weight\n",
        "\n",
        "# we update the model configuration to reflect the new vocabulary size\n",
        "model.config.__dict__['vocab_size'] = new_size\n",
        "model.config.__dict__['_name_or_path'] = f\"{out_dir}/rt5-small\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3arUIzdgm5g",
        "outputId": "38c36b71-cb8f-4aaa-ed70-ac8a8d39ebe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(42473, 250099, 42473, torch.Size([42473, 512]), torch.Size([42473, 512]))"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(kept_ids), max(kept_ids), new_size, new_emb.weight.shape, model.shared.weight.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaR63D3_QVeu",
        "outputId": "c0f263c9-cbe1-436a-b9df-8c162332d83b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of parameters of the original model is 300M\n",
            "The number of parameters of the new model is 88M\n",
            "The new model has 29.2% of the parameters of the original model.\n"
          ]
        }
      ],
      "source": [
        "print(f\"The number of parameters of the original model is {num_params/1e6:.0f}M\")\n",
        "print(f\"The number of parameters of the new model is {parameters_layer(model)/1e6:.0f}M\")\n",
        "print(f\"The new model has {100 * parameters_layer(model) / num_params:.1f}% of the parameters of the original model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug8Ev6CzQVeu"
      },
      "source": [
        "## Reducing the tokenizer\n",
        "Changing the tokenizer is more complicated in this case as it is written in C.\n",
        "To do this we need to download a *.proto* file from the sentencepiece repository and compile it with the protobuf compiler. Then we can use the compiled file to create a new tokenizer. This procedure requires installing the protobuf compiler and using it to compile the *.proto* file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7WXzWP7dE1f"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6ME0bmXQVeu",
        "outputId": "69af2417-7b51-4922-f258-b068f79d0086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-22 22:54:29--  https://raw.githubusercontent.com/google/sentencepiece/master/src/sentencepiece_model.proto\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14023 (14K) [text/plain]\n",
            "Saving to: ‘sentencepiece_model.proto’\n",
            "\n",
            "sentencepiece_model 100%[===================>]  13.69K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-22 22:54:29 (94.4 MB/s) - ‘sentencepiece_model.proto’ saved [14023/14023]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://raw.githubusercontent.com/google/sentencepiece/master/src/sentencepiece_model.proto\n",
        "! protoc --python_out=./out sentencepiece_model.proto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FebRMltGQVev"
      },
      "source": [
        "The procedure is similar to the one used to change the embedding and decoding layers. We create a new tokenizer that maps the new tokens to the old ones. We also need to change the *vocab_size* parameter of the tokenizer to the number of kept tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "6c1381275d7d4776bc4925883217b639",
            "caee282ba181462b96300a49172835cc",
            "f214d907eac244afb26fdba808141862",
            "fe1858e32b3c4edda4084ec9b255c067",
            "cc22db3bf0764969abb40b4602aae4cd",
            "0d0055140df84839b44acef8e8d210ff",
            "104604b4c32c4f2e9a13b10fd17a9a90",
            "e8e74b6f54694316bd0d74e74cad831f",
            "55989b3a0a8742a48368863d2132aedf",
            "7f1012fee2b6413c8c506a7b3e8d599f",
            "7d8e036144fe4f278674fcf109a6a792"
          ]
        },
        "id": "HrzctZHhQVev",
        "outputId": "54ba61c5-d90e-4921-a0f9-9ed9253b3106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The loaded model has pieces: 250100\n",
            "The new pieces: 42473\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c1381275d7d4776bc4925883217b639",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/207627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "smp = tokenizer.sp_model.serialized_model_proto()\n",
        "m = spmp.ModelProto()\n",
        "m.ParseFromString(smp)\n",
        "print(\"The loaded model has pieces:\", len(m.pieces))\n",
        "new_pieces = [m.pieces[idx] for idx in kept_ids]\n",
        "print(\"The new pieces:\", len(new_pieces))\n",
        "\n",
        "for i, p in enumerate(new_pieces):\n",
        "    m.pieces[i].piece = p.piece\n",
        "    m.pieces[i].score = p.score\n",
        "    m.pieces[i].type = p.type\n",
        "\n",
        "# drop the remaining pieces\n",
        "n = len(new_pieces)\n",
        "for i in trange(len(m.pieces) - n):\n",
        "    m.pieces.pop(len(m.pieces) - 1)\n",
        "\n",
        "with open(\"new_sp.model\", \"wb\") as f:\n",
        "    f.write(m.SerializeToString())\n",
        "new_tokenizer = T5Tokenizer(\"new_sp.model\", extra_ids=0)\n",
        "\n",
        "# delete the proto file\n",
        "os.remove(\"sentencepiece_model.proto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PtrEjVzQVev"
      },
      "source": [
        "Finally we can save the new trimmed model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "IQgI2CksQVev"
      },
      "outputs": [],
      "source": [
        "new_tokenizer.save_pretrained(f\"{out_dir}/frt5-small\")\n",
        "model.save_pretrained(f\"{out_dir}/frt5-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLohpuaQVev"
      },
      "source": [
        "## Encoding tests\n",
        "To test if the new tokenizer works correctly we can encode and decode different sentences in different languages. This will also show how differently sentences are tokenized in different languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2WGTTNAQVew",
        "outputId": "a1d9e5b1-7df0-46aa-d2bf-cb8ba0084851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Old Tokenizer Encoding: [1494, 339, 461, 11310, 1]\n",
            "New Tokenizer Encoding: [990, 330, 427, 1274, 34898, 1]\n",
            "\n",
            "Tokens Used (Old Tokenizer): ['▁This', '▁is', '▁an', '▁example', '</s>']\n",
            "Tokens Used (New Tokenizer): ['▁This', '▁is', '▁an', '▁ex', 'ample', '</s>']\n",
            "\n",
            "Old Tokenizer Encoding: [154750, 843, 335, 259, 17421, 1]\n",
            "New Tokenizer Encoding: [35068, 692, 326, 259, 6683, 1]\n",
            "\n",
            "Tokens Used (Old Tokenizer): ['▁Ceci', '▁est', '▁un', '▁', 'exemple', '</s>']\n",
            "Tokens Used (New Tokenizer): ['▁Ceci', '▁est', '▁un', '▁', 'exemple', '</s>']\n"
          ]
        }
      ],
      "source": [
        "english_sentence = \"This is an example\"\n",
        "french_sentence = \"Ceci est un exemple\"\n",
        "\n",
        "# encode the sentence using the old and the new tokenizer\n",
        "encoded_old = tokenizer.encode(english_sentence)\n",
        "encoded_new = new_tokenizer.encode(english_sentence)\n",
        "\n",
        "# print the encoding\n",
        "print(\"Old Tokenizer Encoding:\", encoded_old)\n",
        "print(\"New Tokenizer Encoding:\", encoded_new)\n",
        "print()\n",
        "# show the tokens used\n",
        "tokens_old = tokenizer.convert_ids_to_tokens(encoded_old)\n",
        "tokens_new = new_tokenizer.convert_ids_to_tokens(encoded_new)\n",
        "\n",
        "print(\"Tokens Used (Old Tokenizer):\", tokens_old)\n",
        "print(\"Tokens Used (New Tokenizer):\", tokens_new)\n",
        "print()\n",
        "encoded_old = tokenizer.encode(french_sentence)\n",
        "encoded_new = new_tokenizer.encode(french_sentence)\n",
        "\n",
        "# print the encoding\n",
        "print(\"Old Tokenizer Encoding:\", encoded_old)\n",
        "print(\"New Tokenizer Encoding:\", encoded_new)\n",
        "print()\n",
        "# show the tokens used\n",
        "tokens_old = tokenizer.convert_ids_to_tokens(encoded_old)\n",
        "tokens_new = new_tokenizer.convert_ids_to_tokens(encoded_new)\n",
        "\n",
        "print(\"Tokens Used (Old Tokenizer):\", tokens_old)\n",
        "print(\"Tokens Used (New Tokenizer):\", tokens_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCWDGYQEaOn1"
      },
      "source": [
        "- We can see that while embedding the **English sentence**, there are some differences between the two tokenizers. This is because not all of the *English* tokens have been retained.\n",
        "- On the other hand, when we encode the **French sentence**, the embeddings are the same. This is because all of the *French* tokens have been retained. The tokens have been remapped to the new vocabulary, so the IDs are different, but the embeddings are the same.\n",
        "\n",
        "We can also notice that the decoding works correctly, both for the *English* and *French* tokens.\n",
        "\n",
        "When we talk about *French* or *English* tokens, we refer to the tokens that are used to tokenize most of the sentences in the respective languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqIFD-ucaOn2"
      },
      "source": [
        "## Conclusion\n",
        "We have successfully trimmed the vocabulary of a multilingual T5 model to a monolingual one. We have reduced the number of parameters by 71%. The model can now be used for a single language, in this case, French. The reduction is very significant and can be useful for applications where the model needs to be deployed on devices with limited resources.\n",
        "\n",
        "To be able to measure the difference in performance between the original and the trimmed model, we need to fine-tune the trimmed model on a downstream task."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d0055140df84839b44acef8e8d210ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104604b4c32c4f2e9a13b10fd17a9a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14e181d2807549dabcdd5c2688b64add": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c4b62a0444e4927a35a925454b1ef17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cc14d19698e46c6b5121ead000aff0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3548365e23cc47fc97d6683cc9515e4f",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c4b62a0444e4927a35a925454b1ef17",
            "value": 1000000
          }
        },
        "1d32233015444285a9d8ca54de5345a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25db9decca324ac1af4bb28c834862f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1720e0f21364e22b3c05986ecd79972",
              "IPY_MODEL_1cc14d19698e46c6b5121ead000aff0b",
              "IPY_MODEL_278ac12a13b541118f6642901d324417"
            ],
            "layout": "IPY_MODEL_a9f4b5b52598490386d9cf536c3745e1"
          }
        },
        "278ac12a13b541118f6642901d324417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32a01988cb5447fc9e9f6644e309c098",
            "placeholder": "​",
            "style": "IPY_MODEL_14e181d2807549dabcdd5c2688b64add",
            "value": " 1000000/1000000 [06:10&lt;00:00, 3741.18it/s]"
          }
        },
        "32a01988cb5447fc9e9f6644e309c098": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3548365e23cc47fc97d6683cc9515e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55989b3a0a8742a48368863d2132aedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c1381275d7d4776bc4925883217b639": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caee282ba181462b96300a49172835cc",
              "IPY_MODEL_f214d907eac244afb26fdba808141862",
              "IPY_MODEL_fe1858e32b3c4edda4084ec9b255c067"
            ],
            "layout": "IPY_MODEL_cc22db3bf0764969abb40b4602aae4cd"
          }
        },
        "7d8e036144fe4f278674fcf109a6a792": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f1012fee2b6413c8c506a7b3e8d599f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f4b5b52598490386d9cf536c3745e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caee282ba181462b96300a49172835cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0055140df84839b44acef8e8d210ff",
            "placeholder": "​",
            "style": "IPY_MODEL_104604b4c32c4f2e9a13b10fd17a9a90",
            "value": "100%"
          }
        },
        "cc22db3bf0764969abb40b4602aae4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2e61840f404dd18776195194d7a623": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1720e0f21364e22b3c05986ecd79972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da2e61840f404dd18776195194d7a623",
            "placeholder": "​",
            "style": "IPY_MODEL_1d32233015444285a9d8ca54de5345a7",
            "value": "100%"
          }
        },
        "e8e74b6f54694316bd0d74e74cad831f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f214d907eac244afb26fdba808141862": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e74b6f54694316bd0d74e74cad831f",
            "max": 207627,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55989b3a0a8742a48368863d2132aedf",
            "value": 207627
          }
        },
        "fe1858e32b3c4edda4084ec9b255c067": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1012fee2b6413c8c506a7b3e8d599f",
            "placeholder": "​",
            "style": "IPY_MODEL_7d8e036144fe4f278674fcf109a6a792",
            "value": " 207627/207627 [00:00&lt;00:00, 657555.68it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
